{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar pandas e numpy para trabalhar com Dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importar pyarrow para ler arquivo parquet\n",
    "import pyarrow as pa\n",
    "import  pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o caminho em que se encontra o dataset em parquet\n",
    "path_in = \"../../Datasets/MICRODADOS_ENEM_2019_SAOPAULO_FILTERED.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler o arquivo do dataset\n",
    "df = pd.read_parquet(path_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_to_columns(df, column_prefix, column_name, qtd_columns):\n",
    "    '''\n",
    "    Expande a coluna de um dataframe constituida por um vetor\n",
    "    de strings em uma coluna para cada elemento do vetor. \n",
    "\n",
    "    Parameters:\n",
    "        df (dataframe): dataframe que será expandido\n",
    "        column_prefix (str): prefixo que será colocado no nome das novas colunas\n",
    "        column_name (str): nome das novas colunas\n",
    "        qtd_columns (int): quantidade de novas colunas \n",
    "\n",
    "    Returns:\n",
    "        dataframe: Retorna o dataframe expandido\n",
    "    '''    \n",
    "\n",
    "    new_df = df[column_prefix + column_name].str.split(\"\",0,expand=True)\n",
    "    new_df.drop(columns=[0, qtd_columns], axis=\"columns\", inplace=True)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def remove_extra_columns(dfRespostas, dfGabarito):\n",
    "    '''\n",
    "    Remove as colunas adicionais para a prova de LC,\n",
    "    referentes às questôes da lingua que não foi escolhida\n",
    "    pelo participante  \n",
    "\n",
    "    Parameters:\n",
    "        dfRespostas (dataframe): Dataframe contendo as respostas selecionadas\n",
    "        dfGabarito (dataframe): Dataframe contendo o gabarito das questões\n",
    "\n",
    "    Returns:\n",
    "        dfRespostas, dfGabarito: Retorna os dataframes atualizados\n",
    "    ''' \n",
    "\n",
    "    filter = dfRespostas[1] == \"9\"\n",
    "\n",
    "    for i in range(1,6):\n",
    "        dfRespostas.loc[filter, i] = dfRespostas[i+5]\n",
    "        dfGabarito.loc[filter, i] = dfGabarito[i+5]\n",
    "\n",
    "    dfRespostas.drop(columns=[6,7,8,9,10], inplace=True)\n",
    "    dfGabarito.drop(columns=[6,7,8,9,10], inplace=True)\n",
    "\n",
    "    return dfRespostas, dfGabarito\n",
    "\n",
    "\n",
    "def alternative_to_boolean(dfRespostas, dfGabarito, columnsNames):\n",
    "    '''\n",
    "    Converte a resposta do candidato (Entre 'A' e 'E') em um valor\n",
    "    booleano indicando se acertou (1) ou errou (0) a questão\n",
    "\n",
    "    Parameters:\n",
    "        dfRespostas (dataframe): Dataframe contendo as respostas selecionadas\n",
    "        dfGabarito (dataframe): Dataframe contendo o gabarito das questões\n",
    "        columnsNames (arr): Array contendo os nomes das colunas de respostas\n",
    "\n",
    "    Returns:\n",
    "        dfRespostas: Retorna o dataframe de respostas atualizado\n",
    "    ''' \n",
    "\n",
    "    for column in columnsNames:\n",
    "        conditions = [dfRespostas[column] == dfGabarito[column], pd.isna(dfRespostas[column])]\n",
    "        choices = [1, np.nan]\n",
    "        dfRespostas[column] = np.select(conditions, choices, default=0)\n",
    "    \n",
    "    return dfRespostas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o dicionário contendo os dataframes vazios para cada area\n",
    "dictSubjects = {\"CN\":[], \"MT\":[], \"CH\":[], \"LC\":[]}\n",
    "\n",
    "# Executa as instruções abaixo para cada uma das areas\n",
    "for subject in dictSubjects.keys():\n",
    "\n",
    "    # Quantidade de colunas a serem criadas para as respostas\n",
    "    qtd_columns = 46 if subject != \"LC\" else 51\n",
    "\n",
    "    # Filtrar o dataset original e dividir entre dataset de respostas e gabarito\n",
    "    # convertendo as colunas com vetor de respostas e do gabarito\n",
    "    dfSubject = df[[\"NU_INSCRICAO\", \"TX_RESPOSTAS_\" + subject, \"TX_GABARITO_\" + subject]].dropna()\n",
    "    dfRespostas = vector_to_columns(dfSubject, \"TX_RESPOSTAS_\", subject, qtd_columns)\n",
    "    dfGabarito = vector_to_columns(dfSubject, \"TX_GABARITO_\", subject, qtd_columns)\n",
    "    \n",
    "    # Definir colunas que serão unidas no dataset de respostas\n",
    "    # Se a area for \"LC\", é adocionada mais uma coluna e as colunas extras são removidas\n",
    "    columnsToJoin = [\"NU_INSCRICAO\", \"NU_NOTA_\" + subject, \"CO_PROVA_\" + subject]\n",
    "\n",
    "    if subject == \"LC\":\n",
    "        dfRespostas, dfGabarito = remove_extra_columns(dfRespostas, dfGabarito)\n",
    "        qtd_columns = 46\n",
    "        columnsToJoin.append(\"TP_LINGUA\")\n",
    "\n",
    "    # Definir vetor contendo os nomes das novas colunas,\n",
    "    # com o padrao \"{area}_{numero da questao}\"\n",
    "    columnsNames = [subject + str(i) for i in range(1,qtd_columns)]\n",
    "    dfRespostas.columns = columnsNames\n",
    "    dfGabarito.columns = columnsNames\n",
    "\n",
    "    # Converter as colunas de str para boolean, indicando se acertou ou errou a questao\n",
    "    # Inserir a coluna \"NU_INSCRICAO\" e remover as notas 0\n",
    "    dictSubjects[subject] = alternative_to_boolean(dfRespostas, dfGabarito, columnsNames)\n",
    "    dictSubjects[subject].insert(0, \"NU_INSCRICAO\", dfSubject[\"NU_INSCRICAO\"])\n",
    "    dictSubjects[subject] = dictSubjects[subject].join(df[columnsToJoin].set_index(\"NU_INSCRICAO\"), on=\"NU_INSCRICAO\", how=\"left\")\n",
    "    dictSubjects[subject] = dictSubjects[subject][dictSubjects[subject][\"NU_NOTA_\" + subject]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar os datasets divididos por area\n",
    "for subject, dfSubject in dictSubjects.items():\n",
    "    \n",
    "    table = pa.Table.from_pandas(dfSubject.reset_index(drop=True))\n",
    "    \n",
    "    # Definir onde será salvo o novo dataset filtrado por área\n",
    "    path = f'../../Datasets/MICRODADOS_ENEM_2019_SAOPAULO_BySubject/{subject}.parquet'\n",
    "\n",
    "    # Gerar um parquet da tabela\n",
    "    pq.write_to_dataset(\n",
    "        table,\n",
    "        root_path=path,\n",
    "    )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e774f25fef358570f8855c1820fdc89100b1a0bc15aad31a4e29065a6a0197c3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
