{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import  pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_in = \"../../Datasets/MICRODADOS_ENEM_2019_SAOPAULO_FILTERED.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(path_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_to_columns(df, column_prefix, subject, qtd_columns):    \n",
    "    new_df = df[column_prefix + subject].str.split(\"\",0,expand=True)\n",
    "    new_df = new_df.drop(columns=[0, qtd_columns], axis=\"columns\", inplace=False)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def remove_extra_columns(dfRespostas, dfGabarito):\n",
    "    filter = dfRespostas[1] == \"9\"\n",
    "\n",
    "    for i in range(1,6):\n",
    "        dfRespostas.loc[filter, i] = dfRespostas[i+5]\n",
    "        dfGabarito.loc[filter, i] = dfGabarito[i+5]\n",
    "\n",
    "    dfRespostas.drop(columns=[6,7,8,9,10], inplace=True)\n",
    "    dfGabarito.drop(columns=[6,7,8,9,10], inplace=True)\n",
    "\n",
    "    return dfRespostas, dfGabarito\n",
    "\n",
    "\n",
    "def create_dict_columns(subject, qtd_columns):\n",
    "    columnsNames = [subject + str(i) for i in range(1,qtd_columns)]\n",
    "    dictColumns =  dict(enumerate(columnsNames,1))\n",
    "    \n",
    "    return dictColumns\n",
    "\n",
    "\n",
    "def alternative_to_boolean(dfRespostas, dfGabarito, columnsNames):\n",
    "    for column in columnsNames:\n",
    "        conditions = [dfRespostas[column] == dfGabarito[column], pd.isna(dfRespostas[column])]\n",
    "        choices = [1, np.nan]\n",
    "        dfRespostas[column] = np.select(conditions, choices, default=0)\n",
    "    \n",
    "    return dfRespostas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrayResp = {\"CN\":[], \"MT\":[], \"CH\":[], \"LC\":[]}\n",
    "\n",
    "for subject in arrayResp.keys():\n",
    "\n",
    "    qtd_columns = 46 if subject != \"LC\" else 51\n",
    "\n",
    "    dfSubject = df[[\"NU_INSCRICAO\", \"TX_RESPOSTAS_\" + subject, \"TX_GABARITO_\" + subject]].dropna()\n",
    "    \n",
    "    dfRespostas = vector_to_columns(dfSubject, \"TX_RESPOSTAS_\", subject, qtd_columns)\n",
    "    dfGabarito = vector_to_columns(dfSubject, \"TX_GABARITO_\", subject, qtd_columns)\n",
    "    \n",
    "    if subject == \"LC\":\n",
    "        dfRespostas, dfGabarito = remove_extra_columns(dfRespostas, dfGabarito)\n",
    "        qtd_columns = 46\n",
    "\n",
    "    columnsNames = [subject + str(i) for i in range(1,qtd_columns)]\n",
    "\n",
    "    dfRespostas.columns = columnsNames\n",
    "    dfGabarito.columns = columnsNames\n",
    "\n",
    "    arrayResp[subject] =  alternative_to_boolean(dfRespostas, dfGabarito, columnsNames)\n",
    "    arrayResp[subject].insert(0, \"NU_INSCRICAO\", dfSubject[\"NU_INSCRICAO\"])\n",
    "    arrayResp[subject] = arrayResp[subject].join(df[[\"NU_INSCRICAO\", \"NU_NOTA_\" + subject, \"CO_PROVA_\" + subject]].set_index(\"NU_INSCRICAO\"), on=\"NU_INSCRICAO\", how=\"left\")\n",
    "    arrayResp[subject] = arrayResp[subject][arrayResp[subject][\"NU_NOTA_\" + subject]!=0]\n",
    "\n",
    "del dfSubject\n",
    "del dfRespostas\n",
    "del dfGabarito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject, dfSubject in arrayResp.items():\n",
    "    \n",
    "    table = pa.Table.from_pandas(dfSubject.reset_index(drop=True))\n",
    "    \n",
    "    # Definir onde será salvo o novo dataset filtrado por área\n",
    "    path = f'../../Datasets/BySubject/{subject}_2019_SAOPAULO.parquet'\n",
    "\n",
    "    # Gerar um parquet da tabela\n",
    "    pq.write_to_dataset(\n",
    "        table,\n",
    "        root_path=path,\n",
    "    )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e774f25fef358570f8855c1820fdc89100b1a0bc15aad31a4e29065a6a0197c3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
